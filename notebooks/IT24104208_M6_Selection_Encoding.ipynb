{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc42cbed",
   "metadata": {},
   "source": [
    "# M6 - Label Encoding & Feature Selection\n",
    "\n",
    "**Student ID**: IT24104208  \n",
    "**Focus**: Encode labels and select top features using Chi-squared test  \n",
    "**Visualization**: Feature importance bar plot showing Ï‡Â² scores  \n",
    "**Input**: M5 output (Scaled features)  \n",
    "**Output**: Final processed dataset ready for machine learning\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Encode categorical labels to numeric format\n",
    "2. Apply Chi-squared feature selection to identify most discriminative features\n",
    "3. Create feature importance visualization\n",
    "4. Prepare final dataset for machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880f1d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327a24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from M5 (Scaled features)\n",
    "m5_output_path = '../results/outputs/m5_scaled_features.csv'\n",
    "\n",
    "if os.path.exists(m5_output_path):\n",
    "    print(\"Loading M5 output (Scaled features)...\")\n",
    "    df = pd.read_csv(m5_output_path)\n",
    "    print(f\"Loaded M5 data: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"M5 output not found, loading raw data...\")\n",
    "    df = pd.read_csv('../data/raw/phishing_site_urls.csv')\n",
    "    print(f\"Loaded raw data: {df.shape}\")\n",
    "\n",
    "print(f\"\\nDataset shape: {df.shape}\")\n",
    "print(f\"Label distribution:\\n{df['Label'].value_counts()}\")\n",
    "\n",
    "# Display sample of the scaled data\n",
    "numeric_cols = [col for col in df.columns if col not in ['URL', 'Label']]\n",
    "print(f\"\\nNumeric features available: {len(numeric_cols)}\")\n",
    "print(f\"Features: {numeric_cols}\")\n",
    "print(f\"\\nSample of scaled data:\")\n",
    "print(df[numeric_cols].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd645fc4",
   "metadata": {},
   "source": [
    "## Label Encoding\n",
    "\n",
    "Convert categorical labels ('good', 'bad') to numeric format for machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab365504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M6 Step 1: Label Encoding\n",
    "print(\"M6 Step 1: Label Encoding\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Check original label distribution\n",
    "print(f\"Original labels:\")\n",
    "label_counts = df['Label'].value_counts()\n",
    "print(label_counts)\n",
    "print(f\"\\nLabel percentages:\")\n",
    "print(df['Label'].value_counts(normalize=True).round(4) * 100)\n",
    "\n",
    "# Apply Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df['Label_Encoded'] = label_encoder.fit_transform(df['Label'])\n",
    "\n",
    "print(f\"\\nLabel Encoding Results:\")\n",
    "print(f\"Label mapping: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
    "\n",
    "# Verify encoding\n",
    "encoding_check = df[['Label', 'Label_Encoded']].drop_duplicates().sort_values('Label_Encoded')\n",
    "print(f\"\\nEncoding verification:\")\n",
    "print(encoding_check)\n",
    "\n",
    "# Check encoded label distribution\n",
    "print(f\"\\nEncoded label distribution:\")\n",
    "print(df['Label_Encoded'].value_counts().sort_index())\n",
    "\n",
    "print(\"Label encoding completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abec2931",
   "metadata": {},
   "source": [
    "## Feature Selection using Chi-squared Test\n",
    "\n",
    "Apply statistical feature selection to identify the most discriminative features for phishing detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2f709f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# M6 Step 2: Feature Selection using Chi-squared test\n",
    "print(\"M6 Step 2: Feature Selection using Chi-squared Test\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data for feature selection\n",
    "X = df[numeric_cols]\n",
    "y = df['Label_Encoded']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target vector shape: {y.shape}\")\n",
    "\n",
    "# Ensure all features are non-negative for chi-squared test\n",
    "# (Chi-squared test requires non-negative values)\n",
    "print(f\"\\nChecking feature value ranges:\")\n",
    "feature_ranges = pd.DataFrame({\n",
    "    'Feature': numeric_cols,\n",
    "    'Min': [X[col].min() for col in numeric_cols],\n",
    "    'Max': [X[col].max() for col in numeric_cols],\n",
    "    'Mean': [X[col].mean() for col in numeric_cols]\n",
    "})\n",
    "print(feature_ranges.round(4))\n",
    "\n",
    "# Handle negative values if any (shift to make all values non-negative)\n",
    "X_chi = X.copy()\n",
    "for col in numeric_cols:\n",
    "    if X_chi[col].min() < 0:\n",
    "        X_chi[col] = X_chi[col] - X_chi[col].min()\n",
    "        print(f\"Adjusted {col} to make non-negative\")\n",
    "\n",
    "# Apply Chi-squared feature selection\n",
    "print(f\"\\nApplying Chi-squared feature selection...\")\n",
    "chi2_selector = SelectKBest(score_func=chi2, k='all')\n",
    "X_chi2 = chi2_selector.fit_transform(X_chi, y)\n",
    "\n",
    "# Get Chi-squared scores\n",
    "chi2_scores = chi2_selector.scores_\n",
    "chi2_pvalues = chi2_selector.pvalues_\n",
    "\n",
    "# Create feature importance DataFrame\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': numeric_cols,\n",
    "    'Chi2_Score': chi2_scores,\n",
    "    'P_Value': chi2_pvalues\n",
    "}).sort_values('Chi2_Score', ascending=False)\n",
    "\n",
    "print(f\"\\nChi-squared Feature Importance (Top 10):\")\n",
    "print(feature_importance.head(10).round(6))\n",
    "\n",
    "# Select top K features (let's choose top 10 most important features)\n",
    "k_best = min(10, len(numeric_cols))\n",
    "top_features = feature_importance.head(k_best)['Feature'].tolist()\n",
    "\n",
    "print(f\"\\nSelected Top {k_best} Features:\")\n",
    "for i, feature in enumerate(top_features, 1):\n",
    "    score = feature_importance[feature_importance['Feature'] == feature]['Chi2_Score'].iloc[0]\n",
    "    print(f\"{i:2d}. {feature:<25} (Ï‡Â² = {score:.2f})\")\n",
    "\n",
    "print(\"Feature selection completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb1d5ad",
   "metadata": {},
   "source": [
    "## Additional Feature Analysis\n",
    "\n",
    "Apply mutual information for comparison and comprehensive feature analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c393351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional analysis: Mutual Information for comparison\n",
    "print(\"Additional Analysis: Mutual Information Feature Selection\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Apply Mutual Information feature selection\n",
    "mi_selector = SelectKBest(score_func=mutual_info_classif, k='all')\n",
    "X_mi = mi_selector.fit_transform(X, y)\n",
    "\n",
    "# Get Mutual Information scores\n",
    "mi_scores = mi_selector.scores_\n",
    "\n",
    "# Create comprehensive feature analysis\n",
    "comprehensive_analysis = pd.DataFrame({\n",
    "    'Feature': numeric_cols,\n",
    "    'Chi2_Score': chi2_scores,\n",
    "    'Chi2_Rank': range(1, len(chi2_scores) + 1),\n",
    "    'MI_Score': mi_scores,\n",
    "    'Mean_Good': [df[df['Label'] == 'good'][col].mean() for col in numeric_cols],\n",
    "    'Mean_Bad': [df[df['Label'] == 'bad'][col].mean() for col in numeric_cols]\n",
    "})\n",
    "\n",
    "# Sort by Chi-squared score for ranking\n",
    "comprehensive_analysis = comprehensive_analysis.sort_values('Chi2_Score', ascending=False)\n",
    "comprehensive_analysis['Chi2_Rank'] = range(1, len(comprehensive_analysis) + 1)\n",
    "\n",
    "# Sort by Mutual Information score for ranking\n",
    "comprehensive_analysis_mi = comprehensive_analysis.sort_values('MI_Score', ascending=False)\n",
    "comprehensive_analysis_mi['MI_Rank'] = range(1, len(comprehensive_analysis_mi) + 1)\n",
    "\n",
    "# Merge rankings\n",
    "comprehensive_analysis = comprehensive_analysis.merge(\n",
    "    comprehensive_analysis_mi[['Feature', 'MI_Rank']], on='Feature'\n",
    ").sort_values('Chi2_Score', ascending=False)\n",
    "\n",
    "print(f\"\\nComprehensive Feature Analysis:\")\n",
    "print(comprehensive_analysis.round(4))\n",
    "\n",
    "print(f\"\\nTop Features Comparison:\")\n",
    "print(f\"{'Rank':<4} {'ChiÂ² Top Features':<25} {'MI Top Features':<25}\")\n",
    "print(\"-\" * 60)\n",
    "mi_top_features = comprehensive_analysis.sort_values('MI_Score', ascending=False)['Feature'].head(k_best).tolist()\n",
    "for i in range(k_best):\n",
    "    chi2_feat = top_features[i] if i < len(top_features) else \"\"\n",
    "    mi_feat = mi_top_features[i] if i < len(mi_top_features) else \"\"\n",
    "    print(f\"{i+1:<4} {chi2_feat:<25} {mi_feat:<25}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5716c0c3",
   "metadata": {},
   "source": [
    "## Visualization: Required Feature Importance Bar Plot\n",
    "\n",
    "Create the main visualization: Feature importance bar plot showing Ï‡Â² scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41664f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization with required feature importance plot\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Main required visualization: Feature importance bar plot (Chi-squared scores)\n",
    "ax1 = plt.subplot(2, 2, (1, 2))  # Spans 2 columns\n",
    "\n",
    "# Plot top features by Chi-squared score\n",
    "top_n = min(15, len(feature_importance))  # Show top 15 features\n",
    "plot_data = feature_importance.head(top_n)\n",
    "\n",
    "bars = ax1.barh(range(len(plot_data)), plot_data['Chi2_Score'], \n",
    "                color=plt.cm.viridis(np.linspace(0, 1, len(plot_data))))\n",
    "\n",
    "ax1.set_yticks(range(len(plot_data)))\n",
    "ax1.set_yticklabels(plot_data['Feature'])\n",
    "ax1.set_xlabel('Chi-squared Score (Ï‡Â²)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('Feature Importance Ranking using Chi-squared Test\\n(M6 Required Visualization)', \n",
    "              fontsize=14, fontweight='bold', pad=20)\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, score) in enumerate(zip(bars, plot_data['Chi2_Score'])):\n",
    "    ax1.text(score + max(plot_data['Chi2_Score']) * 0.01, bar.get_y() + bar.get_height()/2,\n",
    "             f'{score:.1f}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "# Invert y-axis to show highest score at top\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Feature Selection Comparison\n",
    "ax2 = plt.subplot(2, 2, 3)\n",
    "comparison_data = comprehensive_analysis.head(10)\n",
    "x_pos = np.arange(len(comparison_data))\n",
    "\n",
    "# Normalize scores for comparison\n",
    "chi2_norm = comparison_data['Chi2_Score'] / comparison_data['Chi2_Score'].max()\n",
    "mi_norm = comparison_data['MI_Score'] / comparison_data['MI_Score'].max()\n",
    "\n",
    "width = 0.35\n",
    "ax2.bar(x_pos - width/2, chi2_norm, width, label='ChiÂ² (normalized)', color='skyblue')\n",
    "ax2.bar(x_pos + width/2, mi_norm, width, label='Mutual Info (normalized)', color='lightcoral')\n",
    "\n",
    "ax2.set_xlabel('Features (Top 10)', fontweight='bold')\n",
    "ax2.set_ylabel('Normalized Score', fontweight='bold')\n",
    "ax2.set_title('Feature Selection Method Comparison', fontweight='bold')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels([f.replace('_', '\\n') for f in comparison_data['Feature']], rotation=45, ha='right')\n",
    "ax2.legend()\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Label Distribution\n",
    "ax3 = plt.subplot(2, 2, 4)\n",
    "label_counts = df['Label'].value_counts()\n",
    "colors = ['#2E8B57', '#DC143C']  # Green for good, red for bad\n",
    "wedges, texts, autotexts = ax3.pie(label_counts.values, labels=label_counts.index, \n",
    "                                  autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "\n",
    "ax3.set_title('Label Distribution\\n(Original Dataset)', fontweight='bold')\n",
    "\n",
    "# Make autopct text bold\n",
    "for autotext in autotexts:\n",
    "    autotext.set_color('white')\n",
    "    autotext.set_fontweight('bold')\n",
    "    autotext.set_fontsize(12)\n",
    "\n",
    "plt.suptitle('M6: Label Encoding & Feature Selection Analysis', fontsize=16, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key insights\n",
    "print(f\"\\nKey Insights from M6 Analysis:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"1. Label Encoding:\")\n",
    "print(f\"   - 'bad' URLs encoded as: {label_encoder.transform(['bad'])[0]}\")\n",
    "print(f\"   - 'good' URLs encoded as: {label_encoder.transform(['good'])[0]}\")\n",
    "print(f\"   - Total samples: {len(df):,}\")\n",
    "\n",
    "print(f\"\\n2. Feature Selection Results:\")\n",
    "print(f\"   - Total features analyzed: {len(numeric_cols)}\")\n",
    "print(f\"   - Top {k_best} features selected based on Chi-squared test\")\n",
    "print(f\"   - Highest Ï‡Â² score: {feature_importance.iloc[0]['Chi2_Score']:.2f} ({feature_importance.iloc[0]['Feature']})\")\n",
    "print(f\"   - Most significant p-value: {feature_importance['P_Value'].min():.2e}\")\n",
    "\n",
    "print(f\"\\n3. Top 5 Most Discriminative Features:\")\n",
    "for i, (_, row) in enumerate(feature_importance.head(5).iterrows(), 1):\n",
    "    print(f\"   {i}. {row['Feature']:<20} (Ï‡Â² = {row['Chi2_Score']:.2f}, p = {row['P_Value']:.2e})\")\n",
    "\n",
    "if feature_importance.iloc[0]['P_Value'] < 0.001:\n",
    "    print(f\"\\nStrong statistical significance detected - features are highly discriminative!\")\n",
    "else:\n",
    "    print(f\"\\nModerate statistical significance - consider additional feature engineering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c702a04",
   "metadata": {},
   "source": [
    "## Final Dataset Preparation\n",
    "\n",
    "Create the final processed dataset ready for machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc80302e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare final datasets\n",
    "print(\"M6 Final Step: Dataset Preparation\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "# Create dataset with all features (scaled)\n",
    "df_all_features = df[['URL', 'Label', 'Label_Encoded'] + numeric_cols].copy()\n",
    "\n",
    "# Create dataset with selected features only\n",
    "df_selected_features = df[['URL', 'Label', 'Label_Encoded'] + top_features].copy()\n",
    "\n",
    "print(f\"Final Dataset Information:\")\n",
    "print(f\"All features dataset shape: {df_all_features.shape}\")\n",
    "print(f\"Selected features dataset shape: {df_selected_features.shape}\")\n",
    "print(f\"Features reduced from {len(numeric_cols)} to {len(top_features)} ({len(top_features)/len(numeric_cols)*100:.1f}%)\")\n",
    "\n",
    "# Create train-test split for demonstration\n",
    "X_all = df_all_features[numeric_cols]\n",
    "X_selected = df_selected_features[top_features]\n",
    "y = df_all_features['Label_Encoded']\n",
    "\n",
    "X_train_all, X_test_all, y_train, y_test = train_test_split(\n",
    "    X_all, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train_sel, X_test_sel, _, _ = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain-Test Split:\")\n",
    "print(f\"Training set: {X_train_all.shape[0]:,} samples\")\n",
    "print(f\"Test set: {X_test_all.shape[0]:,} samples\")\n",
    "print(f\"Class distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "\n",
    "# Feature summary for final dataset\n",
    "print(f\"\\nSelected Features Summary:\")\n",
    "selected_summary = comprehensive_analysis[comprehensive_analysis['Feature'].isin(top_features)].copy()\n",
    "selected_summary = selected_summary.sort_values('Chi2_Score', ascending=False)\n",
    "print(selected_summary[['Feature', 'Chi2_Score', 'MI_Score', 'Mean_Good', 'Mean_Bad']].round(4))\n",
    "\n",
    "# Save final datasets\n",
    "output_dir = '../results/outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save complete processed dataset\n",
    "all_features_path = os.path.join(output_dir, 'm6_final_all_features.csv')\n",
    "df_all_features.to_csv(all_features_path, index=False)\n",
    "print(f\"\\nComplete dataset saved to: {all_features_path}\")\n",
    "\n",
    "# Save selected features dataset\n",
    "selected_features_path = os.path.join(output_dir, 'm6_final_selected_features.csv')\n",
    "df_selected_features.to_csv(selected_features_path, index=False)\n",
    "print(f\"Selected features dataset saved to: {selected_features_path}\")\n",
    "\n",
    "# Save feature importance analysis\n",
    "importance_path = os.path.join(output_dir, 'm6_feature_importance.csv')\n",
    "comprehensive_analysis.to_csv(importance_path, index=False)\n",
    "print(f\"Feature importance analysis saved to: {importance_path}\")\n",
    "\n",
    "# Save label encoder\n",
    "import pickle\n",
    "encoder_path = os.path.join(output_dir, 'm6_label_encoder.pkl')\n",
    "with open(encoder_path, 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "print(f\"ðŸ”§ Label encoder saved to: {encoder_path}\")\n",
    "\n",
    "print(f\"\\nReady for Machine Learning Pipeline Integration\")\n",
    "print(f\"M6 Analysis Complete: Label encoding and feature selection successfully completed\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\nPIPELINE READY FOR MACHINE LEARNING:\")\n",
    "print(f\"   â€¢ Dataset: {len(df):,} URLs processed\")\n",
    "print(f\"   â€¢ Features: {len(top_features)} selected from {len(numeric_cols)} total\")\n",
    "print(f\"   â€¢ Labels: Encoded (0=good, 1=bad)\")\n",
    "print(f\"   â€¢ Data: Scaled and normalized\")\n",
    "print(f\"   â€¢ Quality: Statistical significance confirmed\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
