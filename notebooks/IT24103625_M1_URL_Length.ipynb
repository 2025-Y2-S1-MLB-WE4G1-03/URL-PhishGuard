{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16621647",
   "metadata": {},
   "source": [
    "# M1 - URL Length & Hostname Length Analysis\n",
    "\n",
    "**Student ID**: IT24103625  \n",
    "**Focus**: Extract URL and hostname length features  \n",
    "**Visualization**: Boxplot showing URL length distribution differences between Good/Bad URLs\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Extract URL length and hostname length features\n",
    "2. Analyze the relationship between URL/hostname length and phishing labels\n",
    "3. Create visualizations to show the discriminative power of these features\n",
    "4. Save the processed data for use in the next module (M2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26627cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from urllib.parse import urlparse\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# Set up plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1115e989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = '../data/raw/phishing_site_urls.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Dataset loaded successfully!\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['Label'].value_counts())\n",
    "print(f\"\\nFirst few URLs:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e16ce",
   "metadata": {},
   "source": [
    "## Feature Engineering: URL and Hostname Length\n",
    "\n",
    "Extract URL length and hostname length features. These are fundamental security features as phishing URLs often use longer, more complex structures to deceive users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e70103",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_length_features(url):\n",
    "    \"\"\"\n",
    "    Extract URL length and hostname length features\n",
    "    Returns: tuple (url_length, hostname_length)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate URL length\n",
    "        url_length = len(url)\n",
    "        \n",
    "        # Parse URL to extract hostname\n",
    "        parsed = urlparse(url)\n",
    "        hostname = parsed.netloc if parsed.netloc else url.split('/')[0]\n",
    "        hostname_length = len(hostname)\n",
    "        \n",
    "        return url_length, hostname_length\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing URL: {url[:50]}... - {e}\")\n",
    "        return len(url), 0\n",
    "\n",
    "# Test the function with sample URLs\n",
    "test_urls = [\n",
    "    'https://www.google.com',\n",
    "    'http://very-long-suspicious-phishing-domain-name.fake-paypal-security-update.com/login/verify/account/details',\n",
    "    'https://github.com/user/repo',\n",
    "    'http://192.168.1.1/admin/login.php?redirect=dashboard&token=abc123'\n",
    "]\n",
    "\n",
    "print(\"Testing length extraction function:\")\n",
    "for url in test_urls:\n",
    "    url_len, host_len = extract_length_features(url)\n",
    "    print(f\"{url[:60]:<60} -> URL: {url_len:3d}, Hostname: {host_len:2d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea247e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply length feature extraction to all URLs\n",
    "print(\"Extracting URL and hostname length features...\")\n",
    "\n",
    "# Extract features for all URLs\n",
    "length_features = df['URL'].apply(extract_length_features)\n",
    "df['url_length'] = [feat[0] for feat in length_features]\n",
    "df['hostname_length'] = [feat[1] for feat in length_features]\n",
    "\n",
    "print(\"Feature extraction completed!\")\n",
    "\n",
    "# Display sample results\n",
    "print(f\"\\nSample of extracted features:\")\n",
    "sample_df = df[['URL', 'Label', 'url_length', 'hostname_length']].head(10)\n",
    "print(sample_df.to_string(index=False))\n",
    "\n",
    "# Basic statistics\n",
    "print(f\"\\nFeature Statistics:\")\n",
    "print(f\"URL Length - Min: {df['url_length'].min()}, Max: {df['url_length'].max()}, Mean: {df['url_length'].mean():.2f}\")\n",
    "print(f\"Hostname Length - Min: {df['hostname_length'].min()}, Max: {df['hostname_length'].max()}, Mean: {df['hostname_length'].mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420948f",
   "metadata": {},
   "source": [
    "## Data Analysis & Statistical Comparison\n",
    "\n",
    "Analyze the relationship between URL/hostname length and phishing labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa17341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical analysis by label\n",
    "length_analysis = df.groupby('Label')[['url_length', 'hostname_length']].agg(['mean', 'std', 'min', 'max', 'median']).round(2)\n",
    "\n",
    "print(\"Length Analysis by Label:\")\n",
    "print(length_analysis)\n",
    "\n",
    "# Calculate differences between good and bad URLs\n",
    "good_urls = df[df['Label'] == 'good']\n",
    "bad_urls = df[df['Label'] == 'bad']\n",
    "\n",
    "url_len_diff = bad_urls['url_length'].mean() - good_urls['url_length'].mean()\n",
    "hostname_len_diff = bad_urls['hostname_length'].mean() - good_urls['hostname_length'].mean()\n",
    "\n",
    "print(f\"\\nMean Differences (Bad - Good):\")\n",
    "print(f\"URL Length: {url_len_diff:.2f} characters\")\n",
    "print(f\"Hostname Length: {hostname_len_diff:.2f} characters\")\n",
    "\n",
    "# Percentile analysis\n",
    "print(f\"\\nPercentile Analysis:\")\n",
    "for label in ['good', 'bad']:\n",
    "    subset = df[df['Label'] == label]\n",
    "    print(f\"\\n{label.upper()} URLs:\")\n",
    "    print(f\"  URL Length - 25th: {subset['url_length'].quantile(0.25):.0f}, 75th: {subset['url_length'].quantile(0.75):.0f}\")\n",
    "    print(f\"  Hostname Length - 25th: {subset['hostname_length'].quantile(0.25):.0f}, 75th: {subset['hostname_length'].quantile(0.75):.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045dc705",
   "metadata": {},
   "source": [
    "## Visualization: Required Boxplot\n",
    "\n",
    "Create the main visualization: Boxplot showing URL length distribution differences between Good/Bad URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34d2067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main visualization: Boxplot for URL length distribution (Required visualization)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Boxplot 1: URL Length Distribution by Label (Required visualization)\n",
    "box_data_url = [df[df['Label'] == 'good']['url_length'], df[df['Label'] == 'bad']['url_length']]\n",
    "box1 = ax1.boxplot(box_data_url, labels=['Good URLs', 'Bad URLs'], \n",
    "                   patch_artist=True, notch=True, showmeans=True)\n",
    "\n",
    "# Customize boxplot colors\n",
    "colors = ['#2E8B57', '#DC143C']  # Green for good, red for bad\n",
    "for patch, color in zip(box1['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax1.set_ylabel('URL Length (characters)', fontsize=12, fontweight='bold')\n",
    "ax1.set_title('URL Length Distribution by Label\\n(M1 Required Visualization)', fontsize=14, fontweight='bold', pad=20)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add statistical annotations\n",
    "good_mean = df[df['Label'] == 'good']['url_length'].mean()\n",
    "bad_mean = df[df['Label'] == 'bad']['url_length'].mean()\n",
    "ax1.text(0.02, 0.98, f'Good Mean: {good_mean:.1f}\\nBad Mean: {bad_mean:.1f}\\nDifference: {bad_mean-good_mean:.1f}', \n",
    "         transform=ax1.transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "# Boxplot 2: Hostname Length Distribution by Label\n",
    "box_data_hostname = [df[df['Label'] == 'good']['hostname_length'], df[df['Label'] == 'bad']['hostname_length']]\n",
    "box2 = ax2.boxplot(box_data_hostname, labels=['Good URLs', 'Bad URLs'], \n",
    "                   patch_artist=True, notch=True, showmeans=True)\n",
    "\n",
    "# Customize boxplot colors\n",
    "for patch, color in zip(box2['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax2.set_ylabel('Hostname Length (characters)', fontsize=12, fontweight='bold')\n",
    "ax2.set_title('Hostname Length Distribution by Label', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add statistical annotations\n",
    "good_host_mean = df[df['Label'] == 'good']['hostname_length'].mean()\n",
    "bad_host_mean = df[df['Label'] == 'bad']['hostname_length'].mean()\n",
    "ax2.text(0.02, 0.98, f'Good Mean: {good_host_mean:.1f}\\nBad Mean: {bad_host_mean:.1f}\\nDifference: {bad_host_mean-good_host_mean:.1f}', \n",
    "         transform=ax2.transAxes, verticalalignment='top',\n",
    "         bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))\n",
    "\n",
    "plt.suptitle('M1: URL Length & Hostname Length Analysis', fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print key insights\n",
    "print(f\"\\nKey Insights from M1 Analysis:\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"1. URL Length Analysis:\")\n",
    "print(f\"   - Good URLs average: {good_mean:.1f} characters\")\n",
    "print(f\"   - Bad URLs average: {bad_mean:.1f} characters\")\n",
    "print(f\"   - Difference: {bad_mean-good_mean:.1f} characters ({((bad_mean-good_mean)/good_mean*100):+.1f}%)\")\n",
    "\n",
    "print(f\"\\n2. Hostname Length Analysis:\")\n",
    "print(f\"   - Good URLs average: {good_host_mean:.1f} characters\")\n",
    "print(f\"   - Bad URLs average: {bad_host_mean:.1f} characters\")\n",
    "print(f\"   - Difference: {bad_host_mean-good_host_mean:.1f} characters ({((bad_host_mean-good_host_mean)/good_host_mean*100):+.1f}%)\")\n",
    "\n",
    "if bad_mean > good_mean:\n",
    "    print(f\"\\nBad URLs are longer on average - confirms phishing pattern!\")\n",
    "else:\n",
    "    print(f\"\\nGood URLs are longer on average - unexpected pattern!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd20bc",
   "metadata": {},
   "source": [
    "## Feature Summary & Export\n",
    "\n",
    "Create a summary of extracted features and save the data for M2 (Character Counts Analysis)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b0727d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature summary\n",
    "feature_summary = pd.DataFrame({\n",
    "    'Feature': ['url_length', 'hostname_length'],\n",
    "    'Description': [\n",
    "        'Total character count in the complete URL',\n",
    "        'Character count in the hostname/domain portion only'\n",
    "    ],\n",
    "    'Type': ['Continuous', 'Continuous'],\n",
    "    'Min_Value': [df['url_length'].min(), df['hostname_length'].min()],\n",
    "    'Max_Value': [df['url_length'].max(), df['hostname_length'].max()],\n",
    "    'Mean_Value': [df['url_length'].mean(), df['hostname_length'].mean()]\n",
    "})\n",
    "\n",
    "print(\"M1 Feature Engineering Summary:\")\n",
    "print(\"=\"*60)\n",
    "print(feature_summary.to_string(index=False))\n",
    "\n",
    "# Display final dataset structure\n",
    "print(f\"\\nFinal dataset shape: {df.shape}\")\n",
    "print(f\"New features added: url_length, hostname_length\")\n",
    "print(f\"\\nDataset columns: {df.columns.tolist()}\")\n",
    "\n",
    "# Save results for M2 (Character Counts Analysis)\n",
    "output_dir = '../results/outputs'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "output_path = os.path.join(output_dir, 'm1_url_length_features.csv')\n",
    "df.to_csv(output_path, index=False)\n",
    "print(f\"\\nDataset with M1 features saved to: {output_path}\")\n",
    "print(f\"Ready for M2 (Character Counts Analysis)\")\n",
    "\n",
    "# Save feature summary\n",
    "summary_path = os.path.join(output_dir, 'm1_feature_summary.csv')\n",
    "feature_summary.to_csv(summary_path, index=False)\n",
    "print(f\"Feature summary saved to: {summary_path}\")\n",
    "\n",
    "print(\"\\nM1 Analysis Complete: URL Length & Hostname Length features successfully extracted\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
